{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kostas/anaconda3/envs/p3-ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "\n",
    "random.seed(43)\n",
    "K = 100 # number of poems to train on\n",
    "WINDOW_SIZE = 30\n",
    "LAYER_SIZE = 160\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "TAG_RE = re.compile(r'<[^>]+>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the rich cherry, whose sleek wood,\n",
      "and top with silver petals traced\n",
      "like a strict box its gems encased,\n",
      "has spilt from out that cunning lid,\n",
      "all in an innocent green round,\n",
      "those melting rubies which it hid;\n",
      "with moss ripe-strawberry-encrusted,\n",
      "so birds get half, and minds lapse merry\n",
      "to taste that deep-red, lark’s-bite berry,\n",
      "and blackcap bloom is yellow-dusted.\n",
      "the wren that thieved it in the eaves\n",
      "a trailer of the rose could catch\n",
      "to her poor droopy sloven thatch,\n",
      "and side by side with the wren’s brood—\n",
      "o lovely time of beggar’s luck—\n",
      "opens the quaint and hairy bud;\n",
      "and full and golden is the yield\n",
      "of cows that never have to house,\n",
      "but all night nibble under boughs,\n",
      "or cool their sides in the moist field.\n",
      "into the rooms flow meadow airs,\n",
      "the warm farm baking smell’s blown round.\n",
      "inside and out, and sky and ground\n",
      "are much the same; the wishing star,\n",
      "hesperus, kind and early born,\n",
      "is risen only finger-far;\n",
      "all stars stand close in summer air,\n",
      "and tremble, and look mild as amber;\n",
      "when wicks are lighted in the chamber,\n",
      "they are like stars which settled there.\n",
      "now straightening from the flowery hay,\n",
      "down the still light the mowers look,\n",
      "or turn, because their dreaming shook,\n",
      "and they waked half to other days,\n",
      "when left alone in the yellow stubble\n",
      "the rusty-coated mare would graze.\n",
      "yet thick the lazy dreams are born,\n",
      "another thought can come to mind,\n",
      "but like the shivering of the wind,\n",
      "morning and evening in the corn.\n",
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x97', '\\xa0', '³', 'à', 'á', 'â', 'æ', 'è', 'é', 'í', 'ó', 'ö', 'ø', 'ÿ', 'ɐ', 'ˀ', 'ˈ', 'ː', '̯', '–', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "Total Characters:  170427\n",
      "Total distinct:  83\n",
      "Total Patterns:  167397\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare data\n",
    "\"\"\"\n",
    "\n",
    "def get_wiki_text(title):\n",
    "    response = requests.get(\n",
    "        'https://en.wikipedia.org/w/api.php',\n",
    "        params={\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'prop': 'extracts',\n",
    "            'titles': title,\n",
    "            'redirects': True\n",
    "         }\n",
    "    ).json()\n",
    "\n",
    "    text = ''\n",
    "    for value in response['query']['pages'].values(): text += value['extract']\n",
    "\n",
    "    text = TAG_RE.sub('', text)\n",
    "    return text\n",
    "\n",
    "def get_poems(k=10):\n",
    "    for path in random.sample(glob.glob('data/*/*.json'), k = k):\n",
    "        with open(path) as fi:\n",
    "            poem = \"\\n\".join(json.loads(fi.read())['text']).lower()\n",
    "            yield poem\n",
    "\n",
    "def get_alphabet(text):\n",
    "    return sorted(set(text))\n",
    "\n",
    "poems = list(get_poems(k=K))\n",
    "print(poems[0])\n",
    "\n",
    "# Mix poetry and Maersk\n",
    "maersk = get_wiki_text('Maersk').lower()\n",
    "poems.append(maersk)\n",
    "\n",
    "# Get alphabet\n",
    "poems_joined = ''.join(poems)\n",
    "alphabet = get_alphabet(poems_joined)\n",
    "print(alphabet)\n",
    "\n",
    "n_chars = len(poems_joined)\n",
    "n_distinct = len(alphabet)\n",
    "\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total distinct: \", n_distinct)\n",
    "\n",
    "int_to_char = dict([(i, c) for i, c in enumerate(alphabet)])\n",
    "char_to_oh = dict([(c, np.identity(n_distinct)[i: i+1][0]) for i, c in enumerate(alphabet)])\n",
    "\n",
    "# Create one-hot-encoded training data\n",
    "data_X = []\n",
    "data_y = []\n",
    "for poem in poems:\n",
    "    for i in range(0, len(poem) - WINDOW_SIZE, 1): \n",
    "        seq_in = [char_to_oh[c] for c in poem[i: i + WINDOW_SIZE]]\n",
    "        seq_out = char_to_oh[poem[i+WINDOW_SIZE]]\n",
    "        data_X.append(seq_in)\n",
    "        data_y.append(seq_out)\n",
    "    \n",
    "n_patterns = len(data_X)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "\n",
    "X = np.reshape(data_X, (n_patterns, WINDOW_SIZE, n_distinct))\n",
    "y = np.reshape(data_y, (n_patterns, n_distinct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train\n",
    "\"\"\"\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(LSTM(LAYER_SIZE, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(LSTM(LAYER_SIZE))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open('saved/model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# define the checkpoint\n",
    "#filepath = 'saved/weights-{epoch:02d}-{loss:.4f}.hdf5'\n",
    "filepath = 'saved/weights-{epoch:03d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Train\n",
    "model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 30, 160)           156160    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 160)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 160)               205440    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 83)                13363     \n",
      "=================================================================\n",
      "Total params: 374,963\n",
      "Trainable params: 374,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Seed:\n",
      " \n",
      "i must go down to the seas again, to the lonely sea and the sky,\n",
      "and all i ask is a tall ship and a star to steer her by;\n",
      "and the wheel’s kick and the wind’s song and the white sail’s shaking,\n",
      "and a grey mist on the sea’s face, and a grey dawn breaking.\n",
      "\n",
      "\n",
      "['saved2/weights-041.hdf5', 'saved2/weights-016.hdf5', 'saved2/weights-020.hdf5', 'saved2/weights-036.hdf5', 'saved2/weights-037.hdf5', 'saved2/weights-021.hdf5', 'saved2/weights-001.hdf5', 'saved2/weights-017.hdf5', 'saved2/weights-040.hdf5', 'saved2/weights-026.hdf5', 'saved2/weights-030.hdf5', 'saved2/weights-010.hdf5', 'saved2/weights-006.hdf5', 'saved2/weights-007.hdf5', 'saved2/weights-011.hdf5', 'saved2/weights-031.hdf5', 'saved2/weights-027.hdf5', 'saved2/weights-032.hdf5', 'saved2/weights-024.hdf5', 'saved2/weights-008.hdf5', 'saved2/weights-028.hdf5', 'saved2/weights-004.hdf5', 'saved2/weights-012.hdf5', 'saved2/weights-013.hdf5', 'saved2/weights-005.hdf5', 'saved2/weights-029.hdf5', 'saved2/weights-009.hdf5', 'saved2/weights-025.hdf5', 'saved2/weights-033.hdf5', 'saved2/weights-038.hdf5', 'saved2/weights-002.hdf5', 'saved2/weights-014.hdf5', 'saved2/weights-043.hdf5', 'saved2/weights-034.hdf5', 'saved2/weights-022.hdf5', 'saved2/weights-018.hdf5', 'saved2/weights-019.hdf5', 'saved2/weights-023.hdf5', 'saved2/weights-035.hdf5', 'saved2/weights-042.hdf5', 'saved2/weights-015.hdf5', 'saved2/weights-003.hdf5', 'saved2/weights-039.hdf5']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "Generating 512-character poem after 1 iteration(s):\n",
      "\n",
      "e the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard the shard \n",
      "<EOP>\n",
      "\n",
      "Generating 512-character poem after 11 iteration(s):\n",
      "\n",
      "ainst the shadows of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company sea the shadow of the company\n",
      "<EOP>\n",
      "\n",
      "Generating 512-character poem after 21 iteration(s):\n",
      "\n",
      "ainst the shadow of the secret her hands\n",
      "and the stars of the hand of a parple of the world and the shadow of the spring\n",
      "in the shadow of the shadows of the shadows of the chairs"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-347c41aa325a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generating {}-character poem after {} iteration(s):'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGEN_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_poetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_SEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGEN_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-347c41aa325a>\u001b[0m in \u001b[0;36mgenerate_poetry\u001b[0;34m(seed_text, model, length)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mX_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_distinct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpredicted_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3-ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                              'argument.')\n\u001b[1;32m   1151\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3-ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3-ai/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use model\n",
    "\"\"\"\n",
    "SAVED_DIR = 'saved2'\n",
    "GEN_LENGTH = 512\n",
    "DEFAULT_SEED = \\\n",
    "\"\"\"\n",
    "I must go down to the seas again, to the lonely sea and the sky,\n",
    "And all I ask is a tall ship and a star to steer her by;\n",
    "And the wheel’s kick and the wind’s song and the white sail’s shaking,\n",
    "And a grey mist on the sea’s face, and a grey dawn breaking.\n",
    "\"\"\".lower()\n",
    "\n",
    "def generate_poetry(seed_text, model, length=200):\n",
    "    # seed pattern\n",
    "    pattern = [char_to_oh[c] for c in seed_text[:WINDOW_SIZE]]\n",
    "\n",
    "    # generate characters\n",
    "    for i in range(length):\n",
    "        X_next = np.reshape(pattern, (1, WINDOW_SIZE, n_distinct))\n",
    "        prediction = model.predict(X_next, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        predicted_char = int_to_char[index]\n",
    "        padding = char_to_oh[predicted_char]\n",
    "        pattern.append(padding)\n",
    "        pattern = pattern[1:]\n",
    "        yield predicted_char\n",
    "\n",
    "# load model and weights from disk\n",
    "with open('{}/model.json'.format(SAVED_DIR), 'r') as json_file: \n",
    "    loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.summary()\n",
    "    print()\n",
    "\n",
    "def load_weights(model, epoch):\n",
    "    weights = '{saved_dir}/weights-{epoch:03d}.hdf5'.format(saved_dir=SAVED_DIR, epoch=epoch)\n",
    "    model.load_weights(weights)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "print('Seed:\\n', DEFAULT_SEED)\n",
    "print()\n",
    "\n",
    "paths = glob.glob('{}/weight*'.format(SAVED_DIR))\n",
    "epochs = sorted([int(re.findall(r'weights-(\\d+)', path)[0]) for path in paths])\n",
    "for epoch in epochs[0::10]:\n",
    "    # Set weights on model\n",
    "    load_weights(model, epoch)\n",
    "    # Generate poem\n",
    "    print('Generating {}-character poem after {} iteration(s):'.format(GEN_LENGTH, epoch))\n",
    "    print()\n",
    "    for c in generate_poetry(DEFAULT_SEED, model, length=GEN_LENGTH):\n",
    "        sys.stdout.write(c)\n",
    "    print()\n",
    "    print('<EOP>')        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment = 'the brides are'\n",
    "fragment in ''.join(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " damarance\n",
      "the parts and the correnish propersion of the sea,\n",
      "the soul is the proper craps of the children and the children and the room in the desert of the country of the dead.\n",
      "the brides art the intricate wind a shining removed\n",
      "from the rook is the strings in the short of our life shall reves the tries, but my life span.\n",
      "to consummer that the shadow of the world.\n",
      "then the fire and survices of the country of the dead,\n",
      "the brides are stars of the country of the dead,\n",
      "the brides are stars of the country of the dead,\n",
      "the brides are stars of the country of the dead,\n",
      "the brides are stars of the country of the dead\n",
      "<EOP>\n"
     ]
    }
   ],
   "source": [
    "OLIVE_SEED = \\\n",
    "\"\"\"\n",
    "a ship my ship containers are nice\n",
    "I stuff my containers full of olives and mice\n",
    "the waves lay gently a craddle of money\n",
    "my future is golden from olives and honey\n",
    "\"\"\"\n",
    "\n",
    "BEST_EPOCH = 43\n",
    "#BEST_EPOCH = 41\n",
    "\n",
    "# load model and weights from disk\n",
    "with open('{}/model.json'.format(SAVED_DIR), 'r') as json_file: \n",
    "    loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "\n",
    "load_weights(model, BEST_EPOCH)\n",
    "\n",
    "for c in generate_poetry(OLIVE_SEED, model, length=GEN_LENGTH+106):\n",
    "    sys.stdout.write(c)\n",
    "print()\n",
    "print('<EOP>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did the model spontaneously discover gaelic???\n",
    "\n",
    "\"\"\"\n",
    "maersk oil is an inde that the larine first seamed\n",
    "in the sand a could bu the coust skip and it with the everyt, \n",
    "and the she’s flag to the loved of the where a sand the poir,\n",
    "you beckin me them, the she loved chind it ups.\n",
    "they thought they had dead,\n",
    "a lood and herdy\n",
    "and the way it all the streek in they\n",
    "\n",
    "-- Poet = (2 layers, 128 neuron, 25 poems, 148 epochs)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "by the quait in the african by ever nerver market for the sapping come, \n",
    "the streek boteer in chilling to her the rood ass.\n",
    "but heavents in 1993, he earth he dainter speas, \n",
    "danglush, bird\n",
    "\n",
    "-- Poet = (2 layers, 128 neuron, 25 poems, 148 epochs)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "in a starts nime suppey the ever neart,\n",
    "i pare the donnest,\n",
    "a righ wo reavly he which a stanling.\n",
    "whether when it singes in the sidan\n",
    "\n",
    "-- Poet = (2 layers, 128 neuron, 25 poems, 148 epochs)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
